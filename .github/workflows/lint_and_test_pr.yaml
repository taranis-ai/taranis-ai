name: test and lint

on:
  workflow_dispatch:
  pull_request:

env:
  UV_NO_SYNC: true
  UV_FROZEN: true

jobs:
  test_core:
    name: pytest core
    defaults:
      run:
        working-directory: src/core
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v6
        with:
          enable-cache: true

      - name: Set up Python
        run: uv python install

      - name: Install the project
        run: uv sync --all-extras

      - name: Lint with ruff
        run: uv run ruff check --output-format=github .

      - name: Run tests and capture output
        id: run-tests
        run: |
          set -o pipefail
          uv run pytest | tee pytest_output.txt
          echo "### Test Summary" >> $GITHUB_STEP_SUMMARY
          echo "- **✅ Passed:** $(grep -oP '\d+(?= passed)' pytest_output.txt || echo 0)" >> $GITHUB_STEP_SUMMARY
          echo "- **❌ Failed:** $(grep -oP '\d+(?= failed)' pytest_output.txt || echo 0)" >> $GITHUB_STEP_SUMMARY
          echo "- **⚠️ Skipped:** $(grep -oP '\d+(?= skipped)' pytest_output.txt || echo 0)" >> $GITHUB_STEP_SUMMARY
          echo "- **🚨 Errors:** $(grep -oP '\d+(?= error)' pytest_output.txt || echo 0)" >> $GITHUB_STEP_SUMMARY

  test_frontend:
    name: pytest frontend
    defaults:
      run:
        working-directory: src/frontend
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v6
        with:
          enable-cache: true

      - name: Set up Python
        run: uv python install

      - name: Install the project
        run: uv sync --all-extras

      - name: Lint with ruff
        run: uv run ruff check --output-format=github .

      - name: Run tests and capture output
        id: run-tests
        run: |
          set -o pipefail
          uv run pytest | tee pytest_output.txt
          echo "### Test Summary" >> $GITHUB_STEP_SUMMARY
          echo "- **✅ Passed:** $(grep -oP '\d+(?= passed)' pytest_output.txt || echo 0)" >> $GITHUB_STEP_SUMMARY
          echo "- **❌ Failed:** $(grep -oP '\d+(?= failed)' pytest_output.txt || echo 0)" >> $GITHUB_STEP_SUMMARY
          echo "- **⚠️ Skipped:** $(grep -oP '\d+(?= skipped)' pytest_output.txt || echo 0)" >> $GITHUB_STEP_SUMMARY
          echo "- **🚨 Errors:** $(grep -oP '\d+(?= error)' pytest_output.txt || echo 0)" >> $GITHUB_STEP_SUMMARY

  test_gui:
    name: test gui
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: src/gui
    outputs:
      gui_artifact_name: ${{ steps.set_gui_artifact_name.outputs.gui_artifact_name }}

    steps:
      - uses: actions/checkout@v4
      - name: Install pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 10

      - uses: actions/setup-node@v4
        with:
          node-version: 22
          cache: 'pnpm'
          cache-dependency-path: src/gui/pnpm-lock.yaml

      - name: Install dependencies
        run: pnpm install

      - name: Lint with eslint
        run: pnpm run lint_and_format

      - name: Build frontend
        run: pnpm run build

      - name: Preperae GUI artifact
        id: set_gui_artifact_name
        run: |
          GUI_ARTIFACT_NAME="built-frontend-${{ github.event.pull_request.number || github.run_number }}"
          GUI_ARTIFACT_NAME=${GUI_ARTIFACT_NAME//\//-}
          echo "GUI_ARTIFACT_NAME=${GUI_ARTIFACT_NAME}" >> $GITHUB_ENV
          echo "gui_artifact_name=${GUI_ARTIFACT_NAME}" >> $GITHUB_OUTPUT
          tar -czf ${{ runner.temp }}/${GUI_ARTIFACT_NAME}.tar.gz dist/

      - name: Upload built frontend
        uses: actions/upload-artifact@v4
        with:
          name: ${{ env.GUI_ARTIFACT_NAME }}
          path: ${{ runner.temp }}/${{ env.GUI_ARTIFACT_NAME }}.tar.gz

  e2e_tests:
    name: End-to-End Tests
    runs-on: ubuntu-latest
    needs: [test_core, test_gui, test_frontend]
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v6
        with:
          enable-cache: true

      - name: Set PLAYWRIGHT_BROWSERS_PATH and TRACES_ARTIFACT_NAME
        run: |
          echo "PLAYWRIGHT_BROWSERS_PATH=$HOME/.cache/ms-playwright" >> $GITHUB_ENV
          TRACES_ARTIFACT_NAME="playwright-traces-${{ github.event.pull_request.number || github.run_number }}"
          echo "TRACES_ARTIFACT_NAME=${TRACES_ARTIFACT_NAME//\//-}" >> $GITHUB_ENV

      - name: Check Playwright version consistency in uv.lock files
        run: |
          set -euo pipefail

          FRONTEND_VERSION=$(uv export --frozen --no-hashes --all-extras --directory src/frontend | grep '^playwright==' | cut -d= -f3)
          CORE_VERSION=$(uv export --frozen --no-hashes --all-extras --directory src/core | grep '^playwright==' | cut -d= -f3)

          echo "Frontend playwright version: $FRONTEND_VERSION"
          echo "Core playwright version:     $CORE_VERSION"

          if [ "$FRONTEND_VERSION" != "$CORE_VERSION" ]; then
            echo "::error ::Mismatch in declared playwright versions!"
            echo "::error ::src/frontend declares $FRONTEND_VERSION, but src/core declares $CORE_VERSION."
            echo "::error ::Please run \`uv sync --upgrade --all-extras\` in both folders to align."
            exit 1
          fi

      - name: Set up Python
        working-directory: src/core
        run: uv python install

      - name: Install core
        working-directory: src/core
        run: uv sync --all-extras

      - name: Cache Playwright Browsers
        id: playwright-cache
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: ${{ runner.os }}-playwright

      - name: Install Playwright dependencies
        if: steps.playwright-cache.outputs.cache-hit != 'true'
        working-directory: src/core
        run: uv run playwright install --with-deps chromium

      - name: Download built frontend
        uses: actions/download-artifact@v4
        with:
          name: ${{ needs.test_gui.outputs.gui_artifact_name }}
          path: src/gui/

      - name: Extract Artifact for CI/CD
        working-directory: src/gui
        run: tar xf ${{ needs.test_gui.outputs.gui_artifact_name }}.tar.gz

      - name: Run e2e tests
        id: run_e2e
        working-directory: src/core
        run: uv run pytest --e2e-ci

      - name: Install frontend dependencies
        working-directory: src/frontend
        run: uv sync --all-extras

      - name: Build Tailwind CSS
        working-directory: src/frontend
        run: ./build_tailwindcss.sh

      - name: Run e2e tests frontend
        id: run_e2e_frontend
        working-directory: src/frontend
        run: uv run pytest --e2e-ci

      - name: Upload a e2e-test trace
        uses: actions/upload-artifact@v4
        if: ${{ !cancelled() && (steps.run_e2e.outcome == 'failure' || steps.run_e2e_frontend.outcome == 'failure') }}
        with:
          retention-days: 7
          overwrite: true
          name: ${{ env.TRACES_ARTIFACT_NAME }}
          path: src/**/taranis_ai_*_trace.zip

  test_worker:
    name: pytest worker
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: src/worker
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v6
        with:
          enable-cache: true

      - name: Set up Python
        run: uv python install

      - name: Install worker
        run: uv sync --all-extras

      - name: Install playwright dependencies
        run: uv run playwright install --with-deps chromium

      - name: Lint with ruff
        run: uv run ruff check --output-format=github .

      - name: Run tests and capture output
        id: run-tests
        run: |
          set -o pipefail
          uv run pytest | tee pytest_output.txt
          echo "### Test Summary" >> $GITHUB_STEP_SUMMARY
          echo "- **✅ Passed:** $(grep -oP '\d+(?= passed)' pytest_output.txt || echo 0)" >> $GITHUB_STEP_SUMMARY
          echo "- **❌ Failed:** $(grep -oP '\d+(?= failed)' pytest_output.txt || echo 0)" >> $GITHUB_STEP_SUMMARY
          echo "- **⚠️ Skipped:** $(grep -oP '\d+(?= skipped)' pytest_output.txt || echo 0)" >> $GITHUB_STEP_SUMMARY
          echo "- **🚨 Errors:** $(grep -oP '\d+(?= error)' pytest_output.txt || echo 0)" >> $GITHUB_STEP_SUMMARY

  filter:
    name: Detect Relevant Changes
    runs-on: ubuntu-latest
    outputs:
      code: ${{ steps.filter.outputs.code }}
    steps:
      - uses: actions/checkout@v4
      - uses: dorny/paths-filter@v2
        id: filter
        with:
          filters: |
            code:
              - 'src/core/core/**'
              - 'src/worker/worker/**'
              - 'docker/**'

  human_approval:
    needs: [e2e_tests, filter]
    runs-on: ubuntu-latest
    if: needs.e2e_tests.result == 'success' && needs.filter.outputs.code == 'true'
    outputs:
      should_run: ${{ needs.filter.outputs.code }}
      is_approved:  ${{ steps.pr_approval.outputs.is_approved }}
      pr_sha:       ${{ steps.set_pr.outputs.pr_sha }}

    steps:
      - name: Set PR commit
        id: set_pr
        run: echo "pr_sha=${{ github.event.pull_request.head.sha }}" >> $GITHUB_OUTPUT

      - name: Checkout PR
        uses: actions/checkout@v4
        with:
          ref: ${{ steps.set_pr.outputs.pr_sha }}
          fetch-depth: 0

      - name: Verify human approval
        id: pr_approval
        continue-on-error: true
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          PR_NUMBER="${{ github.event.pull_request.number || github.event.number }}"
          echo "Checking PR #$PR_NUMBER for human approval"
          COUNT=$(gh pr view "$PR_NUMBER" \
            --repo "${{ github.repository }}" \
            --json reviews \
            --jq '
              .reviews
              | map(select(.state=="APPROVED"))
              | map(select(.author.login != "sourcery-ai[bot]"))
              | unique_by(.author.login)
              | length
            ')
          if (( COUNT > 0 )); then
            echo "is_approved=true"  >> $GITHUB_OUTPUT
          else
            echo "is_approved=false" >> $GITHUB_OUTPUT
          fi

  production_compose_test:
    needs: human_approval
    if: needs.human_approval.outputs.should_run == 'true' && needs.human_approval.outputs.is_approved == 'true'
    runs-on: ubuntu-latest

    steps:
      - name: Checkout PR code
        uses: actions/checkout@v4
        with:
          ref: ${{ needs.human_approval.outputs.pr_sha }}
          fetch-depth: 0

      - name: Get latest tag
        id: get_latest_tag
        run: |
          git fetch --tags
          latest_tag=$(git tag --sort=-creatordate | head -n 1)
          echo "tag=$latest_tag" >> $GITHUB_OUTPUT

      - name: Checkout latest tag
        uses: actions/checkout@v4
        with:
          fetch-tags: true
          ref: ${{ steps.get_latest_tag.outputs.tag }}

      - name: Run docker compose for tagged version
        working-directory: docker
        run: |
          cp env.sample .env
          docker compose up --wait core database frontend gui sse rabbitmq collector workers
          docker ps -a
          docker compose down

      - name: Checkout PR commit
        uses: actions/checkout@v4
        with:
          ref: ${{ needs.human_approval.outputs.pr_sha }}
          fetch-depth: 1

      - name: Build Docker images from PR code
        run: |
          chmod +x docker/build_containers.sh
          ./docker/build_containers.sh

      - name: Run docker compose for latest version
        working-directory: docker
        run: |
          cp env.sample .env
          docker volume ls
          docker compose up --wait core database frontend gui sse rabbitmq collector workers
          docker ps -a
          docker compose down

